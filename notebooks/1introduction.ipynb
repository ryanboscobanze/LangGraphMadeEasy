{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0af1b75e",
   "metadata": {},
   "source": [
    "> ## ⚠️ Important Lab Disclaimer\n",
    "> This lab requires API keys (OpenAI, Tavily, OpenWeather) if you want to run the live examples.  \n",
    "> These keys stay only inside the **temporary Udemy lab workspace** and are **not persisted or shared**, but you should still treat them like any other secret.  \n",
    "> Use your own discretion when entering keys, and feel free to **revoke or rotate** them after the lab.  \n",
    "> If you prefer **not** to use real API keys, Copy paste away or download the notebook and run it locally.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b91528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install langchain-openai langchain-core python-dotenv\n",
    "# ! pip install langchain\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efb39ab",
   "metadata": {},
   "source": [
    "This script securely collects three API keys (`OPENAI_API_KEY`, `TAVILY_API_KEY`, `OPENWEATHER_API_KEY`) using `getpass` so your input is hidden.  \n",
    "It then creates/overwrites a `.env` file and writes each key as `NAME=value` on its own line.  \n",
    "Finally, it prints **“Saved .env”** when finished.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "042aeeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved .env\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "names = [\"OPENAI_API_KEY\", \"TAVILY_API_KEY\", \"OPENWEATHER_API_KEY\"]\n",
    "with open(\".env\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for n in names:\n",
    "        f.write(f\"{n}={getpass(f'Enter {n}: ').strip()}\\n\")\n",
    "print(\"Saved .env\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a9b1651",
   "metadata": {},
   "source": [
    "This code locates the nearest `.env` file in the current working directory (using `find_dotenv`) and loads its key–value pairs into the environment (using `load_dotenv`).  \n",
    "It does **not** overwrite any existing environment variables because `override=False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b20288f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "env_path = find_dotenv(usecwd=True)\n",
    "load_dotenv(env_path, override=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0100a018",
   "metadata": {},
   "source": [
    "This code creates an OpenAI chat model (`ChatOpenAI`) with a fixed temperature of 0, sends it a prompt about planning a short New York trip, and returns the model’s response.  \n",
    "`response.content` gives the raw text, and `response.pretty_print()` displays the response in a cleaner, formatted way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c5a2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d424408a",
   "metadata": {},
   "source": [
    "You can swap **any supported chat model** \n",
    "\n",
    "LangChain lets you swap chat models easily—just change the import and the model name. Here are concise examples showing different providers:\n",
    "\n",
    "```python\n",
    "# OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "chat = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Anthropic (Claude)\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "chat = ChatAnthropic(model=\"claude-3-haiku\")\n",
    "\n",
    "# Google (Gemini)\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "chat = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "\n",
    "# Mistral AI\n",
    "from langchain_mistralai import ChatMistralAI\n",
    "chat = ChatMistralAI(model=\"mistral-small-latest\")\n",
    "\n",
    "# Groq (fast inference with open-weights models)\n",
    "from langchain_groq import ChatGroq\n",
    "chat = ChatGroq(model=\"mixtral-8x7b\")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d291183b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43bb4e51",
   "metadata": {},
   "source": [
    "This sends a prompt to the chat model and returns its generated response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35e83bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat.invoke(\"Plan a simple 1-night/2-day trip to New York for a family of four.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d51744ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Day 1:\\n- Arrive in New York City in the morning and check into a family-friendly hotel in Midtown Manhattan.\\n- Head to Times Square to take in the bustling atmosphere and grab a quick lunch at one of the many restaurants in the area.\\n- Visit the iconic Empire State Building for panoramic views of the city.\\n- Walk to Bryant Park and enjoy some leisure time exploring the park and maybe even catching a free outdoor movie or performance.\\n- Have dinner at a family-friendly restaurant in the area before heading back to the hotel for the night.\\n\\nDay 2:\\n- Start the day with a visit to Central Park, where you can rent bikes or take a leisurely stroll through the park.\\n- Head to the American Museum of Natural History to explore the exhibits and learn about the natural world.\\n- Grab lunch at a nearby cafe or food truck before heading to the Museum of Modern Art to see some world-renowned works of art.\\n- Spend the afternoon shopping and exploring Fifth Avenue, stopping at iconic stores like Tiffany & Co. and Saks Fifth Avenue.\\n- End the trip with a visit to Rockefeller Center to see the famous ice skating rink and maybe catch a show at Radio City Music Hall before heading back home.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 247, 'prompt_tokens': 26, 'total_tokens': 273, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-CgdjgJRRisyMUTpX2j1K2NOQaOzhF', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--660e7b73-67e2-4ca1-a44d-477a0a9a262f-0', usage_metadata={'input_tokens': 26, 'output_tokens': 247, 'total_tokens': 273, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5360479e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Day 1:\\n- Arrive in New York City in the morning and check into a family-friendly hotel in Midtown Manhattan.\\n- Head to Times Square to take in the bustling atmosphere and grab a quick lunch at one of the many restaurants in the area.\\n- Visit the iconic Empire State Building for panoramic views of the city.\\n- Walk to Bryant Park and enjoy some leisure time exploring the park and maybe even catching a free outdoor movie or performance.\\n- Have dinner at a family-friendly restaurant in the area before heading back to the hotel for the night.\\n\\nDay 2:\\n- Start the day with a visit to Central Park, where you can rent bikes or take a leisurely stroll through the park.\\n- Head to the American Museum of Natural History to explore the exhibits and learn about the natural world.\\n- Grab lunch at a nearby cafe or food truck before heading to the Museum of Modern Art to see some world-renowned works of art.\\n- Spend the afternoon shopping and exploring Fifth Avenue, stopping at iconic stores like Tiffany & Co. and Saks Fifth Avenue.\\n- End the trip with a visit to Rockefeller Center to see the famous ice skating rink and maybe catch a show at Radio City Music Hall before heading back home.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f2a6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Day 1:\n",
      "- Arrive in New York City in the morning and check into a family-friendly hotel in Midtown Manhattan.\n",
      "- Head to Times Square to take in the bustling atmosphere and grab a quick lunch at one of the many restaurants in the area.\n",
      "- Visit the iconic Empire State Building for panoramic views of the city.\n",
      "- Walk to Bryant Park and enjoy some leisure time exploring the park and maybe even catching a free outdoor movie or performance.\n",
      "- Have dinner at a family-friendly restaurant in the area before heading back to the hotel for the night.\n",
      "\n",
      "Day 2:\n",
      "- Start the day with a visit to Central Park, where you can rent bikes or take a leisurely stroll through the park.\n",
      "- Head to the American Museum of Natural History to explore the exhibits and learn about the natural world.\n",
      "- Grab lunch at a nearby cafe or food truck before heading to the Museum of Modern Art to see some world-renowned works of art.\n",
      "- Spend the afternoon shopping and exploring Fifth Avenue, stopping at iconic stores like Tiffany & Co. and Saks Fifth Avenue.\n",
      "- End the trip with a visit to Rockefeller Center to see the famous ice skating rink and maybe catch a show at Radio City Music Hall before heading back home.\n"
     ]
    }
   ],
   "source": [
    "response.pretty_print() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6cd88f6",
   "metadata": {},
   "source": [
    "This utility provides a single function, `show_any`, that **pretty-prints any LLM output** in notebooks.  \n",
    "It detects the object type (messages, LangGraph state dicts, streams, or raw OpenAI responses), formats them with Markdown/JSON, optionally truncates long text, and displays metadata like tool calls and usage when available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110ec13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "from typing import Any, Iterable\n",
    "import json, inspect\n",
    "\n",
    "def _md(s: str): display(Markdown(s))\n",
    "def _j(obj): return \"```json\\n\" + json.dumps(obj, indent=2, default=str) + \"\\n```\"\n",
    "\n",
    "def show_any(result: Any, show_usage=True, show_meta=True, truncate: int | None = None):\n",
    "    \"\"\"\n",
    "    Pretty-print *anything* you might get back from an LLM call:\n",
    "    - LangChain Messages / LangGraph state dicts\n",
    "    - Lists/streams of messages\n",
    "    - Raw OpenAI SDK responses (chat/responses)\n",
    "    \"\"\"\n",
    "    # 0) Optional simple truncation of big contents\n",
    "    def _maybe_trunc(s: str) -> str:\n",
    "        if truncate and isinstance(s, str) and len(s) > truncate:\n",
    "            return s[:truncate] + f\"\\n… [truncated {len(s)-truncate} chars]\"\n",
    "        return s\n",
    "\n",
    "    # A) LangGraph/agent state: {\"messages\": [...]}\n",
    "    if isinstance(result, dict) and \"messages\" in result and isinstance(result[\"messages\"], Iterable):\n",
    "        _md(\"### Conversation\")\n",
    "        for i, msg in enumerate(result[\"messages\"], 1):\n",
    "            role = getattr(msg, \"type\", msg.__class__.__name__)\n",
    "            _md(f\"**[{i}] {role}**\")\n",
    "            content = getattr(msg, \"content\", None)\n",
    "            if content is not None:\n",
    "                _md(_maybe_trunc(content) if isinstance(content, str) else _j(content))\n",
    "\n",
    "            # Tool calls / function_call live in different places across providers\n",
    "            tool_calls = getattr(msg, \"tool_calls\", None)\n",
    "            ak = getattr(msg, \"additional_kwargs\", {}) or {}\n",
    "            func_call = ak.get(\"function_call\") or ak.get(\"tool_calls\")\n",
    "            if tool_calls or func_call:\n",
    "                _md(\"**Tool calls**\")\n",
    "                _md(_j(tool_calls or func_call))\n",
    "\n",
    "            # ToolMessage info\n",
    "            name = getattr(msg, \"name\", None)\n",
    "            if name: _md(f\"*tool name:* `{name}`\")\n",
    "\n",
    "            if show_meta:\n",
    "                meta = getattr(msg, \"response_metadata\", None)\n",
    "                if meta: _md(\"**response_metadata**\\n\" + _j(meta))\n",
    "        if show_usage and hasattr(result, \"usage_metadata\") and result.usage_metadata:\n",
    "            _md(\"### Usage / metadata\\n\" + _j(result.usage_metadata))\n",
    "        return\n",
    "\n",
    "    # B) Single LangChain message (AIMessage, HumanMessage, ToolMessage, etc.)\n",
    "    if hasattr(result, \"content\") or hasattr(result, \"response_metadata\"):\n",
    "        role = getattr(result, \"type\", result.__class__.__name__)\n",
    "        _md(f\"### {role}\")\n",
    "        content = getattr(result, \"content\", None)\n",
    "        if content is not None:\n",
    "            _md(_maybe_trunc(content) if isinstance(content, str) else _j(content))\n",
    "        tool_calls = getattr(result, \"tool_calls\", None)\n",
    "        ak = getattr(result, \"additional_kwargs\", {}) or {}\n",
    "        func_call = ak.get(\"function_call\") or ak.get(\"tool_calls\")\n",
    "        if tool_calls or func_call:\n",
    "            _md(\"**Tool calls**\\n\" + _j(tool_calls or func_call))\n",
    "        name = getattr(result, \"name\", None)\n",
    "        if name: _md(f\"*tool name:* `{name}`\")\n",
    "        if show_meta:\n",
    "            meta = getattr(result, \"response_metadata\", None)\n",
    "            if meta: _md(\"**response_metadata**\\n\" + _j(meta))\n",
    "        if show_usage and hasattr(result, \"usage_metadata\") and result.usage_metadata:\n",
    "            _md(\"### Usage / metadata\\n\" + _j(result.usage_metadata))\n",
    "        return\n",
    "\n",
    "    # C) Iterable of messages/chunks (streams, lists)\n",
    "    if isinstance(result, Iterable) and not isinstance(result, (str, bytes, dict)):\n",
    "        for item in result: show_any(item, show_usage=show_usage, show_meta=show_meta, truncate=truncate)\n",
    "        return\n",
    "\n",
    "    # D) Raw OpenAI SDK objects (chat.completions / responses)\n",
    "    # Heuristic: has .id and .choices or .output\n",
    "    if hasattr(result, \"id\") and (hasattr(result, \"choices\") or hasattr(result, \"output\")):\n",
    "        _md(\"### OpenAI raw response\")\n",
    "        rid = getattr(result, \"id\", None)\n",
    "        model = getattr(result, \"model\", None)\n",
    "        if rid or model: _md(_j({\"id\": rid, \"model\": model}))\n",
    "        if hasattr(result, \"choices\"):  # chat.completions\n",
    "            for i, ch in enumerate(result.choices, 1):\n",
    "                _md(f\"**Choice {i} — finish_reason:** `{getattr(ch, 'finish_reason', None)}`\")\n",
    "                msg = getattr(ch, \"message\", None)\n",
    "                if msg and getattr(msg, \"content\", None):\n",
    "                    _md(_maybe_trunc(msg.content))\n",
    "                if getattr(msg, \"tool_calls\", None):\n",
    "                    _md(\"**Tool calls**\\n\" + _j(msg.tool_calls))\n",
    "        elif hasattr(result, \"output\"):  # responses.create\n",
    "            _md(\"**Output**\\n\" + _j(result.output))\n",
    "        return\n",
    "\n",
    "    # E) Fallback: show whatever it is as JSON\n",
    "    try:\n",
    "        _md(_j(result if not inspect.isgenerator(result) else list(result)))\n",
    "    except Exception:\n",
    "        _md(f\"```\\n{str(result)}\\n```\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e43e8bdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### ai"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Day 1:\n",
       "- Arrive in New York City in the morning and check into a family-friendly hotel in Midtown Manhattan.\n",
       "- Head to Times Square to take in the bustling atmosphere and grab a quick lunch at one of the many restaurants in the area.\n",
       "- Visit the iconic Empire State Building for panoramic views of the city.\n",
       "- Walk to Bryant Park and enjoy some leisure time exploring the park and maybe even catching a free outdoor movie or performance.\n",
       "- Have dinner at a family-friendly restaurant in the area before heading back to the hotel for the night.\n",
       "\n",
       "Day 2:\n",
       "- Start the day with a visit to Central Park, where you can rent bikes or take a leisurely stroll through the park.\n",
       "- Head to the American Museum of Natural History to explore the exhibits and learn about the natural world.\n",
       "- Grab lunch at a nearby cafe or food truck before heading to the Museum of Modern Art to see some world-renowned works of art.\n",
       "- Spend the afternoon shopping and exploring Fifth Avenue, stopping at iconic stores like Tiffany & Co. and Saks Fifth Avenue.\n",
       "- End the trip with a visit to Rockefeller Center to see the famous ice skating rink and maybe catch a show at Radio City Music Hall before heading back home."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**response_metadata**\n",
       "```json\n",
       "{\n",
       "  \"token_usage\": {\n",
       "    \"completion_tokens\": 247,\n",
       "    \"prompt_tokens\": 26,\n",
       "    \"total_tokens\": 273,\n",
       "    \"completion_tokens_details\": {\n",
       "      \"accepted_prediction_tokens\": 0,\n",
       "      \"audio_tokens\": 0,\n",
       "      \"reasoning_tokens\": 0,\n",
       "      \"rejected_prediction_tokens\": 0\n",
       "    },\n",
       "    \"prompt_tokens_details\": {\n",
       "      \"audio_tokens\": 0,\n",
       "      \"cached_tokens\": 0\n",
       "    }\n",
       "  },\n",
       "  \"model_name\": \"gpt-3.5-turbo-0125\",\n",
       "  \"system_fingerprint\": null,\n",
       "  \"id\": \"chatcmpl-CgdjgJRRisyMUTpX2j1K2NOQaOzhF\",\n",
       "  \"service_tier\": \"default\",\n",
       "  \"finish_reason\": \"stop\",\n",
       "  \"logprobs\": null\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Usage / metadata\n",
       "```json\n",
       "{\n",
       "  \"input_tokens\": 26,\n",
       "  \"output_tokens\": 247,\n",
       "  \"total_tokens\": 273,\n",
       "  \"input_token_details\": {\n",
       "    \"audio\": 0,\n",
       "    \"cache_read\": 0\n",
       "  },\n",
       "  \"output_token_details\": {\n",
       "    \"audio\": 0,\n",
       "    \"reasoning\": 0\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_any(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159a59f7",
   "metadata": {},
   "source": [
    "This code prints key metadata from an LLM response: model name, finish reason, prompt/output/total token counts, and the response’s unique run ID. It reads these values from `response.response_metadata` and displays them in a simple, readable format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "497ec1cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== KEY META ===\n",
      "Model       : gpt-3.5-turbo-0125\n",
      "Finish      : stop\n",
      "Prompt toks : 26\n",
      "Output toks : 247\n",
      "Total toks  : 273\n",
      "Run ID      : run--660e7b73-67e2-4ca1-a44d-477a0a9a262f-0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n=== KEY META ===\")\n",
    "meta = response.response_metadata \n",
    "usage = meta.get(\"token_usage\")\n",
    "print(\"Model       :\", meta.get(\"model_name\"))\n",
    "print(\"Finish      :\", meta.get(\"finish_reason\"))  # 'stop' means ended naturally\n",
    "print(\"Prompt toks :\", usage.get(\"prompt_tokens\"))\n",
    "print(\"Output toks :\", usage.get(\"completion_tokens\"))\n",
    "print(\"Total toks  :\", usage.get(\"total_tokens\"))\n",
    "print(\"Run ID      :\", response.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1fc2f7",
   "metadata": {},
   "source": [
    "This builds a message list with a system role and a human query, sends both to the chat model, and prints the model’s final response content.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c96fb0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 1:\n",
      "- Morning: Visit Central Park for a leisurely walk, playgrounds, and maybe a boat ride at the lake.\n",
      "- Afternoon: Head to the American Museum of Natural History for interactive exhibits and the famous dinosaur skeletons.\n",
      "- Evening: Explore Times Square for its bright lights, street performers, and family-friendly restaurants.\n",
      "\n",
      "Day 2:\n",
      "- Morning: Visit the Statue of Liberty and Ellis Island for a dose of history and amazing views of the city skyline.\n",
      "- Afternoon: Explore the Intrepid Sea, Air & Space Museum for hands-on exhibits of historic aircraft and ships.\n",
      "- Evening: Enjoy a Broadway show suitable for the whole family.\n",
      "\n",
      "Remember to check for any age restrictions or special events at each attraction before your visit. Have a great trip!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a concise, friendly travel planner. Prioritize kid-friendly options when asked.\"),\n",
    "    HumanMessage(content=\"Plan a 1N/2D trip to New York for 2 adults + 2 kids.\")\n",
    "]\n",
    "response = chat.invoke(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7298940e",
   "metadata": {},
   "source": [
    "This creates two chat models with different temperatures (“spicy” and “calm”), sends them the same system and human messages, and prints how each model responds differently based on creativity settings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa796661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spicy version:\n",
      " \"Perk up your day with a brew-tiful cup of joy!\"\n",
      "\n",
      "Calm version:\n",
      " \"Awake your inner wizard with every sip at Brewed Spells Coffee Co.\"\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "spicy = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0.9)\n",
    "calm  = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0.0)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a fun, imaginative assistant.\"),\n",
    "    HumanMessage(content=\"Invent a quirky one-sentence slogan for a coffee shop.\"),\n",
    "]\n",
    "\n",
    "print(\"Spicy version:\\n\", spicy.invoke(messages).content)\n",
    "print(\"\\nCalm version:\\n\", calm.invoke(messages).content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27b3485",
   "metadata": {},
   "source": [
    "This streams the model’s response chunk-by-chunk and prints each piece as it arrives, showing how streaming output unfolds in real time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2006b99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\"\n",
      "Aw\n",
      "ake\n",
      " your\n",
      " inner\n",
      " wizard\n",
      " with\n",
      " every\n",
      " sip\n",
      " at\n",
      " Brew\n",
      "ed\n",
      " Spells\n",
      " Coffee\n",
      " Co\n",
      ".\"\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Streaming demo\n",
    "from sys import stdout\n",
    "for ch in calm.stream(messages):\n",
    "    print(ch.content or \"\")\n",
    "stdout.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52704522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "easiest_langgraph",
   "language": "python",
   "name": "easiest_langgraph"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
